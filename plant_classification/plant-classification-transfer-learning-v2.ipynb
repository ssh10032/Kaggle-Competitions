{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18648,"databundleVersionId":1026645,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:18.221477Z","iopub.execute_input":"2024-11-25T07:51:18.222104Z","iopub.status.idle":"2024-11-25T07:51:19.037696Z","shell.execute_reply.started":"2024-11-25T07:51:18.222061Z","shell.execute_reply":"2024-11-25T07:51:19.036751Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport os\n\nseed = 50\nos.environ['PYTHONHASHSEED']=str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:19.039385Z","iopub.execute_input":"2024-11-25T07:51:19.039869Z","iopub.status.idle":"2024-11-25T07:51:21.825659Z","shell.execute_reply.started":"2024-11-25T07:51:19.039828Z","shell.execute_reply":"2024-11-25T07:51:21.824979Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:21.826701Z","iopub.execute_input":"2024-11-25T07:51:21.827174Z","iopub.status.idle":"2024-11-25T07:51:21.886802Z","shell.execute_reply.started":"2024-11-25T07:51:21.827136Z","shell.execute_reply":"2024-11-25T07:51:21.886044Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:21.888338Z","iopub.execute_input":"2024-11-25T07:51:21.888702Z","iopub.status.idle":"2024-11-25T07:51:21.924823Z","shell.execute_reply.started":"2024-11-25T07:51:21.888674Z","shell.execute_reply":"2024-11-25T07:51:21.923988Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(train,\n                               test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                               random_state=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:21.925745Z","iopub.execute_input":"2024-11-25T07:51:21.925992Z","iopub.status.idle":"2024-11-25T07:51:22.450111Z","shell.execute_reply.started":"2024-11-25T07:51:21.925939Z","shell.execute_reply":"2024-11-25T07:51:22.449382Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False):\n        super().__init__()\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id + '.jpg'\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        if self.is_test:\n            return image\n        else:\n            label = np.argmax(self.df.iloc[idx, 1:5])\n            return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:22.451191Z","iopub.execute_input":"2024-11-25T07:51:22.451550Z","iopub.status.idle":"2024-11-25T07:51:22.611083Z","shell.execute_reply.started":"2024-11-25T07:51:22.451523Z","shell.execute_reply":"2024-11-25T07:51:22.610224Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ntransform_train = A.Compose([\n    A.Resize(450, 650),\n    A.RandomBrightnessContrast(brightness_limit=0.2,contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30,\n        p=0.3\n    ),\n    A.OneOf([A.Emboss(p=1),\n            A.Sharpen(p=1),\n            A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:22.612092Z","iopub.execute_input":"2024-11-25T07:51:22.612320Z","iopub.status.idle":"2024-11-25T07:51:23.542080Z","shell.execute_reply.started":"2024-11-25T07:51:22.612298Z","shell.execute_reply":"2024-11-25T07:51:23.541117Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/opt/conda/lib/python3.10/site-packages/albumentations/core/validation.py:45: UserWarning: This augmenter is very slow. Try to use ``ElasticTransformation`` instead, which is at least 10x faster.\n  original_init(self, **validated_kwargs)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"transform_test = A.Compose([\n    A.Resize(450, 650),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:23.543203Z","iopub.execute_input":"2024-11-25T07:51:23.543562Z","iopub.status.idle":"2024-11-25T07:51:23.548105Z","shell.execute_reply.started":"2024-11-25T07:51:23.543532Z","shell.execute_reply":"2024-11-25T07:51:23.547025Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:23.549309Z","iopub.execute_input":"2024-11-25T07:51:23.549841Z","iopub.status.idle":"2024-11-25T07:51:23.557379Z","shell.execute_reply.started":"2024-11-25T07:51:23.549802Z","shell.execute_reply":"2024-11-25T07:51:23.556566Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:23.560390Z","iopub.execute_input":"2024-11-25T07:51:23.560745Z","iopub.status.idle":"2024-11-25T07:51:23.569283Z","shell.execute_reply.started":"2024-11-25T07:51:23.560709Z","shell.execute_reply":"2024-11-25T07:51:23.568400Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7bdb6cf95b70>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size=batch_size,\n                         shuffle=True, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)\nloader_valid = DataLoader(dataset_valid, batch_size=batch_size,\n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:23.570253Z","iopub.execute_input":"2024-11-25T07:51:23.570474Z","iopub.status.idle":"2024-11-25T07:51:23.577538Z","shell.execute_reply.started":"2024-11-25T07:51:23.570451Z","shell.execute_reply":"2024-11-25T07:51:23.576754Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:23.578406Z","iopub.execute_input":"2024-11-25T07:51:23.578638Z","iopub.status.idle":"2024-11-25T07:51:34.541025Z","shell.execute_reply.started":"2024-11-25T07:51:23.578615Z","shell.execute_reply":"2024-11-25T07:51:34.540029Z"}},"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=6209cba362cf996a0f5a663f09e948bc3ef242dcd8b0be1d16e1d8eac2a132d8\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\n# pretrained num_classes 1000 -> transfer learning num_classes 4\n\n# method 1 : define num_classes\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4)\n\nmodel.to(device)\n\n# method 2 : modify fc layer output\n\"\"\"\nmodel = EfficientNet.from_pretrained('efficientnet-b7')\nmodel._fc = nn.Sequential(\n    nn.Linear(model._fc.in_features, fc.out_features),\n    nn.ReLU(),\n    nn.Dropout(p=0.5),\n    nn.Linear(model._fc.out_features=4)\n)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:34.542639Z","iopub.execute_input":"2024-11-25T07:51:34.543143Z","iopub.status.idle":"2024-11-25T07:51:37.231930Z","shell.execute_reply.started":"2024-11-25T07:51:34.543102Z","shell.execute_reply":"2024-11-25T07:51:37.230982Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n100%|██████████| 254M/254M [00:01<00:00, 256MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b7\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"\\nmodel = EfficientNet.from_pretrained('efficientnet-b7')\\nmodel._fc = nn.Sequential(\\n    nn.Linear(model._fc.in_features, fc.out_features),\\n    nn.ReLU(),\\n    nn.Dropout(p=0.5),\\n    nn.Linear(model._fc.out_features=4)\\n)\\n\""},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch.nn as nn\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:51:37.233121Z","iopub.execute_input":"2024-11-25T07:51:37.233368Z","iopub.status.idle":"2024-11-25T07:51:38.092750Z","shell.execute_reply.started":"2024-11-25T07:51:37.233345Z","shell.execute_reply":"2024-11-25T07:51:38.092071Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from transformers import get_cosine_schedule_with_warmup\nepochs = 39\n\nscheduler = get_cosine_schedule_with_warmup(optimizer,\n                                           num_warmup_steps=len(loader_train)*3,\n                                           num_training_steps=len(loader_train)*epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T07:54:44.496786Z","iopub.execute_input":"2024-11-25T07:54:44.497699Z","iopub.status.idle":"2024-11-25T07:54:44.681174Z","shell.execute_reply.started":"2024-11-25T07:54:44.497662Z","shell.execute_reply":"2024-11-25T07:54:44.680271Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom tqdm.notebook import tqdm\n\nfor epoch in range(epochs):\n    \n    model.train()\n    epoch_train_loss = 0\n    \n    for images, labels in tqdm(loader_train):\n\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n        epoch_train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    print(f'epoch [{epoch+1}/{epochs}] train_loss : {epoch_train_loss/len(loader_train):.4f}')\n    \n    # validation loop\n    model.eval()\n    epoch_valid_loss = 0\n    pred_lists = []\n    true_onehot_list = []\n        \n    with torch.no_grad():\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n\n            preds = torch.softmax(outputs.cpu(), dim=1).numpy()\n            true_onehot = torch.eye(4, device=device)[labels].cpu().numpy() \n            \n            pred_lists.extend(preds)\n            true_onehot_list.extend(true_onehot)\n\n    print(f'epoch [{epoch+1}/{epochs}] epoch_valid_loss : {epoch_valid_loss/len(loader_valid):.4f} / ROC AUC : {roc_auc_score(true_onehot_list, pred_lists):.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T08:01:44.297583Z","iopub.execute_input":"2024-11-25T08:01:44.298158Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db58e64c2f56475ebe0f05cda4fbb4d7"}},"metadata":{}},{"name":"stdout","text":"epoch [1/39] train_loss : 1.2767\nepoch [1/39] epoch_valid_loss : 0.6686 / ROC AUC : 0.9097\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52f5085c4e904719b94db31a50e8efec"}},"metadata":{}},{"name":"stdout","text":"epoch [2/39] train_loss : 0.5623\nepoch [2/39] epoch_valid_loss : 0.2439 / ROC AUC : 0.9576\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55d17e7c6c34ba7831df426306d5e4b"}},"metadata":{}},{"name":"stdout","text":"epoch [3/39] train_loss : 0.3983\nepoch [3/39] epoch_valid_loss : 0.2014 / ROC AUC : 0.9640\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19e5804f75ce479a822cd90b97ccd173"}},"metadata":{}},{"name":"stdout","text":"epoch [4/39] train_loss : 0.2658\nepoch [4/39] epoch_valid_loss : 0.3647 / ROC AUC : 0.9667\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3389de92e9eb4d01950c72a4ec76224e"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}