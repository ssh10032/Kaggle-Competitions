{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-28T06:55:31.889801Z","iopub.status.busy":"2024-11-28T06:55:31.889403Z","iopub.status.idle":"2024-11-28T06:55:31.895927Z","shell.execute_reply":"2024-11-28T06:55:31.894596Z","shell.execute_reply.started":"2024-11-28T06:55:31.889768Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T06:58:49.729417Z","iopub.status.busy":"2024-11-28T06:58:49.729028Z","iopub.status.idle":"2024-11-28T06:58:49.738142Z","shell.execute_reply":"2024-11-28T06:58:49.737070Z","shell.execute_reply.started":"2024-11-28T06:58:49.729384Z"},"trusted":true},"outputs":[],"source":["import torch\n","import random\n","import numpy as np\n","import os\n","\n","seed = 50\n","os.environ['PYTHONHASHSEED']=str(seed)\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.enabled = False"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T06:59:17.731839Z","iopub.status.busy":"2024-11-28T06:59:17.731415Z","iopub.status.idle":"2024-11-28T06:59:17.737111Z","shell.execute_reply":"2024-11-28T06:59:17.735848Z","shell.execute_reply.started":"2024-11-28T06:59:17.731799Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T06:59:20.850300Z","iopub.status.busy":"2024-11-28T06:59:20.849886Z","iopub.status.idle":"2024-11-28T06:59:20.855941Z","shell.execute_reply":"2024-11-28T06:59:20.854645Z","shell.execute_reply.started":"2024-11-28T06:59:20.850264Z"},"trusted":true},"outputs":[],"source":["data_path = '/home/baebro/nipa_ws/Pneumonia Binary Classification/chest_xray/'\n","\n","train_path = data_path + 'train/'\n","valid_path = data_path +'val/'\n","test_path = data_path + 'test/'"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T07:10:09.208716Z","iopub.status.busy":"2024-11-28T07:10:09.208277Z","iopub.status.idle":"2024-11-28T07:10:09.216660Z","shell.execute_reply":"2024-11-28T07:10:09.215198Z","shell.execute_reply.started":"2024-11-28T07:10:09.208677Z"},"trusted":true},"outputs":[],"source":["from torchvision import transforms\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((250, 250)),\n","    transforms.CenterCrop(180),\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomVerticalFlip(0.2),\n","    transforms.RandomRotation(20),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((250, 250)),\n","    transforms.CenterCrop(180),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T07:15:18.398369Z","iopub.status.busy":"2024-11-28T07:15:18.397935Z","iopub.status.idle":"2024-11-28T07:15:21.425761Z","shell.execute_reply":"2024-11-28T07:15:21.424707Z","shell.execute_reply.started":"2024-11-28T07:15:18.398334Z"},"trusted":true},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","\n","datasets_train = ImageFolder(root=train_path, transform=transform_train)\n","datasets_valid = ImageFolder(root=valid_path, transform=transform_test)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T07:24:22.818250Z","iopub.status.busy":"2024-11-28T07:24:22.817791Z","iopub.status.idle":"2024-11-28T07:24:22.827283Z","shell.execute_reply":"2024-11-28T07:24:22.826169Z","shell.execute_reply.started":"2024-11-28T07:24:22.818214Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fb0393fdcb0>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","g = torch.Generator()\n","g.manual_seed(0)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-28T07:27:32.459244Z","iopub.status.busy":"2024-11-28T07:27:32.458831Z","iopub.status.idle":"2024-11-28T07:27:32.465338Z","shell.execute_reply":"2024-11-28T07:27:32.464030Z","shell.execute_reply.started":"2024-11-28T07:27:32.459209Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 8\n","\n","loader_train = DataLoader(dataset=datasets_train, batch_size=batch_size,\n","                         shuffle=True, worker_init_fn=seed_worker,\n","                         generator=g, num_workers=2)\n","loader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size,\n","                         shuffle=False, worker_init_fn=seed_worker,\n","                         generator=g, num_workers=2)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n"]},{"data":{"text/plain":["EfficientNet(\n","  (_conv_stem): Conv2dStaticSamePadding(\n","    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n","    (static_padding): ZeroPad2d((0, 1, 0, 1))\n","  )\n","  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_blocks): ModuleList(\n","    (0): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        32, 8, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        8, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (1): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n","        (static_padding): ZeroPad2d((0, 1, 0, 1))\n","      )\n","      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        96, 4, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        4, 96, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (2): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (3): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n","        (static_padding): ZeroPad2d((1, 2, 1, 2))\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (4): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (5): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n","        (static_padding): ZeroPad2d((0, 1, 0, 1))\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (6-7): 2 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        480, 20, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        20, 480, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (8): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        480, 20, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        20, 480, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (9-10): 2 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        672, 28, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        28, 672, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (11): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n","        (static_padding): ZeroPad2d((1, 2, 1, 2))\n","      )\n","      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        672, 28, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        28, 672, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (12-14): 3 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (15): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","  )\n","  (_conv_head): Conv2dStaticSamePadding(\n","    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n","    (static_padding): Identity()\n","  )\n","  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","  (_dropout): Dropout(p=0.2, inplace=False)\n","  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n","  (_swish): MemoryEfficientSwish()\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from efficientnet_pytorch import EfficientNet\n","\n","model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["model parameter : 4010110\n"]}],"source":["print('model parameter :', sum(param.numel() for param in model.parameters()))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from tqdm.notebook import tqdm\n","\n","def train(model, loader_train, loader_valid, criterion, optimizer, scheduler=None, epochs=10, save_file='model_state_dict.pth'):\n","\n","    valid_loss_min = np.inf\n","\n","    for epoch in range(epochs):\n","\n","        print(f'epoch [{epoch+1}/{epochs}]')\n","        model.train()\n","        epoch_train_loss = 0\n","\n","        # mini batch train loop\n","        for images, labels in loader_train:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            \n","            epoch_train_loss + loss.item()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if scheduler != None:\n","                scheduler.step()\n","\n","        print(f'\\ttrain loss : {epoch_train_loss/len(loader_train):4f}')\n","\n","        model.eval()\n","        epoch_valid_loss = 0\n","        preds_list = []\n","        true_list = []\n","\n","        # mini batch validation loop\n","        with torch.no_grad():\n","            for images, labels in loader_valid:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                epoch_valid_loss += loss.item()\n","\n","                preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n","                true = labels.cpu().numpy()\n","\n","                preds_list.extend(preds)\n","                true_list.extend(true)\n","        print(f'\\tvalid loss : {epoch_valid_loss/len(loader_valid):4f}')\n","\n","        val_accuracy_score = accuracy_score(true_list, preds_list)\n","        val_recall = recall_score(true_list, preds_list)\n","        val_f1_score = f1_score(true_list, preds_list)\n","\n","        print(f'accuracy : {val_accuracy_score:.4f} / recall : {val_recall:.4f} / f1 score : {val_f1_score:.4f}')\n","\n","        if epoch_valid_loss <= valid_loss_min:\n","            print(f'\\t### valid loss decrease ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). model saved')\n","            torch.save(model.state_dict(), save_file)\n","            valid_loss_min = epoch_valid_loss\n","\n","    return torch.load(save_file)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch [1/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 0.756567\n","accuracy : 0.7500 / recall : 0.6250 / f1 score : 0.7143\n","\t### valid loss decrease (inf --> 1.5131). model saved\n","epoch [2/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 1.077170\n","accuracy : 0.3750 / recall : 0.6250 / f1 score : 0.5000\n","epoch [3/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 0.985954\n","accuracy : 0.5625 / recall : 0.7500 / f1 score : 0.6316\n","epoch [4/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 0.991221\n","accuracy : 0.5625 / recall : 0.1250 / f1 score : 0.2222\n","epoch [5/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 0.881279\n","accuracy : 0.6875 / recall : 1.0000 / f1 score : 0.7619\n","epoch [6/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 6.374924\n","accuracy : 0.5000 / recall : 1.0000 / f1 score : 0.6667\n","epoch [7/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 1.539275\n","accuracy : 0.5625 / recall : 1.0000 / f1 score : 0.6957\n","epoch [8/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 0.699769\n","accuracy : 0.6875 / recall : 0.8750 / f1 score : 0.7368\n","\t### valid loss decrease (1.5131 --> 1.3995). model saved\n","epoch [9/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 2.837976\n","accuracy : 0.6250 / recall : 1.0000 / f1 score : 0.7273\n","epoch [10/10]\n","\ttrain loss : 0.000000\n","\tvalid loss : 0.338174\n","accuracy : 0.8125 / recall : 0.8750 / f1 score : 0.8235\n","\t### valid loss decrease (1.3995 --> 0.6763). model saved\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_133311/843039258.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(save_file)\n"]}],"source":["model_state_dict = train(model=model, loader_train=loader_train, loader_valid=loader_valid,criterion=criterion, optimizer=optimizer, \n","                        save_file='/home/baebro/nipa_ws/Pneumonia Binary Classification/model_state_dict.pth')"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(model_state_dict)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["datasets_test = ImageFolder(root=test_path, transform=transform_test)\n","\n","loader_test = DataLoader(dataset=datasets_test, batch_size=batch_size,\n","                        shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=2)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def predict(model, loader_test, return_true=False):\n","    model.eval()\n","    preds_list = []\n","    true_list = []\n","\n","    with torch.no_grad():\n","        for images, labels in loader_test:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","\n","            preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n","            true = labels.cpu().numpy()\n","\n","            preds_list.extend(preds)\n","            true_list.extend(true)\n","\n","    if return_true:\n","        return true_list, preds_list\n","    else:\n","        preds_list"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["true_list, preds_list = predict(model=model, loader_test=loader_test, return_true=True)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["##### final pred score #####\n","accuracy score : 0.8510\n","recall score : 0.9359\n","f1 score : 0.8870\n"]}],"source":["print('#'*5, 'final pred score', '#'*5)\n","print(f'accuracy score : {accuracy_score(true_list,preds_list):.4f}')\n","print(f'recall score : {recall_score(true_list, preds_list):.4f}')\n","print(f'f1 score : {f1_score(true_list, preds_list):.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":17810,"sourceId":23812,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3.10.15 ('mp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"vscode":{"interpreter":{"hash":"75fe21128fcfacce69d1e29e597ca9ba6f67d76a760b48a77174c70425a216bc"}}},"nbformat":4,"nbformat_minor":4}
